{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import packages and read the data\n\n"},{"metadata":{},"cell_type":"markdown","source":"Import the packages needed for the analysis.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport plotly.express as px\nplt.style.use('ggplot')\n\nfrom typing import Tuple, List\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.svm import SVC\nfrom sklearn.impute import SimpleImputer, MissingIndicator\nfrom sklearn.pipeline import FeatureUnion, make_pipeline, Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.base import TransformerMixin\n\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Do data exploration\n\n"},{"metadata":{},"cell_type":"markdown","source":"Using the processes presented by Hadley:\n\n[https://r4ds.had.co.nz/exploratory-data-analysis.html](https://r4ds.had.co.nz/exploratory-data-analysis.html)\n\nTwo types of questions\n\n-   What type of variation occurs within my variables?\n-   What type of covariation occurs between my variables?\n\nLet's visualize the categorical variables!\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"train.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see, looking at describe and the data description on kaggle that,\n\n-   Survived (which is out dependent variable)\n-   Pclass,\n-   Sex,\n-   Cabin,\n-   Embarked\n\nare our categorical variables.\n\nLet's visualize the proportion of survived to not survived\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"s = train.Survived.value_counts()\ns.index = [\"No\", \"Yes\"]\ns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.bar(\n    x=s.index,\n    height=s,\n    color=['darkred', 'darkblue']\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find proportions of the survived against the non-survived\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"s / sum(s)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can visualize how many survived amongst a subset of our categorical variables.\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"cat_variables = [\n    'Pclass',\n    'Sex',\n    'Embarked'\n]\nfig, ax = plt.subplots(2, 3, figsize=(10, 10))\nrows, cols = range(2), range(4)\nfor row in rows:\n    for cat_var, col in zip(cat_variables, cols):\n        d = train.loc[train.Survived == row]\n        sns.countplot(\n            x=cat_var,\n            data=train.loc[train.Survived == row],\n            ax = ax[row, col]\n        )\n        ax[row, col].set_title(\"Survived == \" + str(d.Survived.iloc[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From which we recognize that the Pclass and Embarked has the potential of being strong predictors.\n\nFor other categorical variables we have to do some data mendling, such as Cabin, which consists of multiple cabins  for each passenger. Also we are able to subset the deck from the cabin numers, which might give us an indication of how good the predictor is.\n\nIntuitively, the deck number should be a rather strong predictor, since the lower the deck, the more the passenger had to climbed to get to the top deck.\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Extract the cabins data and split into Deck and numberx\ncabins = train.Cabin.str.split(\" \", expand=True).fillna(np.nan)\nf = lambda col: col.str.extract(r'([a-zA-Z]+)(\\d+)')\ncabins_split = pd.concat(\n    [f(cabins[col_label]) for col_label in cabins.columns], \n    axis=1\n)\nls = [\n    \"Deck_0\", \"Room_0\",\n    \"Deck_1\", \"Room_1\",\n    \"Deck_2\", \"Room_2\",\n    \"Deck_3\", \"Room_3\"\n]\ncabins_split.columns = ls\ncabins_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the missing values, we are imputing with \"Missing\", which will be handled by the one-hot encoding\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"cabins_split.fillna(\"Missing\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge the datasets\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"t = pd.concat([\n    train.drop(columns=[\"Cabin\"]),\n    cabins_split\n], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"t.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"t_sorted = t.sort_values(\"Deck_0\")\nsns.catplot(\n    x=\"Deck_0\",\n    col=\"Survived\",\n    kind=\"count\",\n    data=t_sorted.loc[t_sorted.Deck_0 != \"Missing\"],\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(\n    x=\"Deck_0\",\n    hue=\"Survived\",\n    data=t_sorted.loc[t_sorted.Deck_0 != \"Missing\"]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The second plot tells a bit more of the deck variable. Maybe our model will be able to pick out based\n  on the info from this, especially from those thatwere on the B, D, E, and F decks since these have great discrepancies between those who survived and those who didnt.\n\nJust to check let's visualize deck 2 too.\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(\n    x=\"Deck_1\",\n    hue=\"Survived\",\n    data=t_sorted.loc[t_sorted.Deck_1 != \"Missing\"]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I suppose the multiple cabins for 1 person suggests that they travelled multiple people. That is already\n  captured in other features\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(1, 4, figsize=(13, 5))\nfor i in range(0, 4):\n    sns.countplot(\n        x=\"Deck_\" + str(i),\n        hue=\"Survived\",\n        data=t_sorted,\n        ax=ax[i]\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also visualize our continuous variables:\n\n-   Age,\n-   Sibsp\n-   Parch\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"con_variables = [\n    \"Age\",\n    \"SibSp\",\n    \"Parch\"\n]\nf, axs = plt.subplots(1, 3, figsize=(15, 10))\nfor k, var in enumerate(con_variables):\n    sns.histplot(\n        data=train,\n        x=var,\n        hue=\"Survived\",\n        ax=axs[k]\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Do data transformation and drop variables, e.g. transform categorical variables to dummy variables.\n\n"},{"metadata":{},"cell_type":"markdown","source":"Use a data preparation function, to do all prepping on both the training and test sample\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"def prepare_sample(df: pd.DataFrame, y_label: str='Survived') -> Tuple[pd.DataFrame, pd.Series]:\n    labels = ['PassengerId'] if y_label is None else ['PassengerId', y_label]\n\n    # Extract the cabins data and split into Deck and numberx\n    cabins = df.Cabin.str.split(\" \", expand=True).fillna(np.nan)\n    f = lambda col: col.str.extract(r'([a-zA-Z]+)(\\d+)')\n    c_split = pd.concat(\n        [f(cabins[col_label]) for col_label in cabins.columns], \n        axis=1\n    )\n    ls = [\n        \"Deck_0\", \"Room_0\",\n        \"Deck_1\", \"Room_1\",\n        \"Deck_2\", \"Room_2\",\n        \"Deck_3\", \"Room_3\"\n    ]\n    c_split.columns = ls\n    t = pd.concat([df.drop(\"Cabin\", axis=1), c_split], axis=1)\n    # Drop unnecessary columns\n    X = t.drop(\n        labels=labels + ['Ticket', 'Name'],\n        axis=1\n    )\n    y = None if y_label is None else df[y_label]\n\n    return X, y\n\nX, y = prepare_sample(\n    df=train\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run modelling\n\n"},{"metadata":{},"cell_type":"markdown","source":"Conduct modelling, by running randomized search cv for multiple parameters\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Specify classifiers\nclfs = {\n    'rf': RandomForestClassifier(random_state=0),\n}\n# Setup pipelines for variable types\nnumeric_transformer = Pipeline(\n    steps=[\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', StandardScaler())\n    ]\n)\nls = [\n    \"Deck_0\", \"Room_0\",\n    \"Deck_1\", \"Room_1\",\n    \"Deck_2\", \"Room_2\",\n    \"Deck_3\", \"Room_3\"\n]\ncategorical_features = ['Pclass', 'Sex', 'Embarked'] + ls\ncategorical_transformer = Pipeline(\n    steps=[\n        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ]\n)\n# Set variable types\nnumeric_features=[\n    \"Age\",\n    \"SibSp\",\n    \"Parch\"\n]\n# Make transofmer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ]\n)\nclf = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier',  xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42))\n])\n# Setup hyperparameter grid\nparam_grid = {\n    \"classifier__colsample_bytree\": np.arange(0.3, 0.7, 0.1),\n    \"classifier__gamma\": np.arange(0, 0.5, 0.1),\n    \"classifier__learning_rate\": np.arange(0.01, 0.1, 0.01), # default 0.1 \n}\ng = GridSearchCV(\n    cv=5,\n    estimator=clf,\n    param_grid=param_grid,\n    scoring='accuracy'\n).fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"g.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use Gridsearch results to predict on the test data\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test, y_test = prepare_sample(test, None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions = g.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit predictions\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"import datetime as dt\nt = dt.datetime.today().strftime(\"%d%m%Y\")\nsubmission = pd.concat([\n    test.PassengerId,\n    pd.Series(predictions)\n], axis=1)\nsubmission.columns = ['PassengerId', 'Survived']\nsubmission.to_csv(f\"./submissions/submission_{t}.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import os\nos.system(f\"kaggle competitions submit -c titanic -f submissions/submission_{t}.csv -m 'Submission {t}'\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}